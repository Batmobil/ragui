from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers.string import StrOutputParser

# Use a powerful model for analysis and generation
# Replace with your preferred LLM setup (ensure API key is set)
# llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0)
# Using a placeholder for execution without API key:
from langchain_core.language_models.fake import FakeStreamingListLLM
llm = FakeStreamingListLLM(responses=["Okay, analysis complete.", "Okay, new prompt generated."])


def fetch_data(state: AgentState) -> AgentState:
    """Fetches all necessary data using the tools based on the prompt version to improve."""
    print(f"\n--- Node: fetch_data (Improving Version: {state['prompt_version_to_improve']}) ---")
    version = state['prompt_version_to_improve']

    current_prompt = get_previous_prompt(version)
    if not current_prompt:
        # Cannot proceed without the prompt to improve
        # In a real app, you might want error handling or a different flow
        print(f"Error: Prompt version {version} not found.")
        # Add a message to indicate failure? Or raise Exception?
        # For now, we'll add a message and let it potentially fail later
        state['messages'].append(HumanMessage(content=f"System Error: Could not find prompt version {version}."))
        state['current_prompt_text'] = None # Explicitly set to None
        # Return state, subsequent nodes need to handle None gracefully
        return state

    state['current_prompt_text'] = current_prompt
    state['kg_guidelines'] = get_general_kg_guidelines()
    state['low_score_feedback'] = sample_feedback_records(score_filters={'max_score': 0.5})
    state['high_score_feedback'] = sample_feedback_records(score_filters={'min_score': 0.8})
    state['aggregated_feedback'] = aggregate_feedbacks(prompt_version=version)
    state['previous_extractions'] = get_previous_extracted_records_sample(prompt_version=version, num_samples=3)

    # Analyze domain terms from provided doc samples
    state['domain_analysis'] = analyze_domain_terminology(state['business_doc_samples'])

    # Analyze structure of previous TTL outputs
    ttl_outputs = [ext['ttl'] for ext in state['previous_extractions'] if 'ttl' in ext]
    state['structure_analysis'] = analyze_ontology_structure(ttl_outputs)

    # Add a summary message for context if using message-based state
    state['messages'].append(HumanMessage(content=f"Data fetched for improving prompt version {version}. Ready for analysis."))

    print("--- fetch_data complete ---")
    return state


def analyze_performance(state: AgentState) -> AgentState:
    """Analyzes the fetched data to identify strengths, weaknesses, and areas for prompt improvement."""
    print("\n--- Node: analyze_performance ---")

    if not state.get('current_prompt_text'):
         state['analysis_summary'] = "Analysis skipped: Current prompt text is missing."
         state['messages'].append(AIMessage(content=state['analysis_summary']))
         print(state['analysis_summary'])
         return state

    # Construct a detailed prompt for the LLM
    analysis_prompt_template = ChatPromptTemplate.from_messages([
        ("system", """You are an expert prompt engineer specializing in ontology extraction and alignment from text.
        Analyze the provided data about a previous prompt's performance (version {prompt_version_to_improve}) and suggest improvements.

        **Input Data:**
        1.  **Current Prompt Text:** The prompt being evaluated.
        2.  **KG Guidelines:** General best practices for KG/ontology work.
        3.  **Low Score Feedback:** Examples of poor performance (score < 0.5) with comments.
        4.  **High Score Feedback:** Examples of good performance (score > 0.8) with comments.
        5.  **Aggregated Feedback:** Overall statistics (avg score, common issues).
        6.  **Previous Extractions (TTL Samples):** Examples of the TTL output generated by the current prompt.
        7.  **Domain Terminology Analysis:** Analysis of key terms, acronyms, ambiguities in source documents.
        8.  **Ontology Structure Analysis:** Analysis of the structural quality of the generated TTL.

        **Your Task:**
        Synthesize all this information into a concise analysis. Identify:
        - What worked well (based on high scores, good extractions)?
        - What were the main problems (based on low scores, aggregated issues, structural analysis, domain analysis)?
        - Connect specific problems to potential weaknesses in the current prompt text.
        - Identify missed opportunities based on domain/structure analysis and KG guidelines.
        - Conclude with specific, actionable recommendations for how to modify the prompt. Focus on clarity, constraints, examples, handling specific terms/structures, and alignment instructions.
        """),
        ("human", """Analyze the performance of prompt version {prompt_version_to_improve}.

        **Current Prompt (Version {prompt_version_to_improve}):**
        ```
        {current_prompt_text}
        ```

        **KG Guidelines:**
        {kg_guidelines}

        **Low Score Feedback:**
        {low_score_feedback}

        **High Score Feedback:**
        {high_score_feedback}

        **Aggregated Feedback:**
        {aggregated_feedback}

        **Previous Extractions (TTL Samples):**
        ```ttl
        {previous_extractions}
        ```

        **Domain Terminology Analysis:**
        {domain_analysis}

        **Ontology Structure Analysis:**
        {structure_analysis}

        **Analysis and Recommendations:**
        """)
    ])

    analysis_chain = analysis_prompt_template | llm | StrOutputParser()

    # Prepare input dictionary, handling potential None values gracefully
    input_data = {k: state.get(k, "N/A") for k in [
        "prompt_version_to_improve", "current_prompt_text", "kg_guidelines",
        "low_score_feedback", "high_score_feedback", "aggregated_feedback",
        "previous_extractions", "domain_analysis", "structure_analysis"
    ]}
    # Format lists/dicts nicely for the prompt
    input_data["low_score_feedback"] = "\n".join(map(str, input_data["low_score_feedback"])) if input_data["low_score_feedback"] != "N/A" else "N/A"
    input_data["high_score_feedback"] = "\n".join(map(str, input_data["high_score_feedback"])) if input_data["high_score_feedback"] != "N/A" else "N/A"
    input_data["previous_extractions"] = "\n---\n".join(map(lambda x: str(x.get('ttl', 'Invalid Extraction Format')), input_data["previous_extractions"])) if input_data["previous_extractions"] != "N/A" else "N/A"


    # --- Mock LLM Call ---
    # In a real run, this invokes the LLM. Here we simulate it.
    print("--- Simulating LLM call for analysis ---")
    # Based on the mock data, a potential real analysis might look like this:
    mock_analysis = f"""
    Analysis of Prompt Version {state['prompt_version_to_improve']}:

    **Strengths:**
    - Prompt successfully guided extraction of some relationships (e.g., Feature-Component requires).
    - Attempted alignment with specified classes (e.g., :Employee).
    - Explicit request for TTL format and namespace was generally followed.

    **Weaknesses & Problems:**
    1.  **Inconsistent Property Naming:** Feedback and structure analysis (`:managed_By`) show the 'camelCase' instruction wasn't strictly enforced or followed by the LLM. (Connects to Prompt: "Ensure consistency in property names (use camelCase)").
    2.  **Ontology Alignment Failures:** Feedback and structure analysis indicate alignment issues (e.g., `:SoftwareComponent` used instead of the requested `:SoftwareModule`). (Connects to Prompt: "Align extracted concepts with existing ontology classes...").
    3.  **Ambiguous Term Handling:** Domain analysis identified 'Manager' (Role or Person?) and 'legacy system'. The prompt doesn't give specific instructions on how to handle these, leading to potential inconsistency or errors. (Connects to Prompt: Lack of specific guidance).
    4.  **Potential Misclassification:** Feedback mentioned 'CEO as Department' (though from v1, illustrates a risk if prompt isn't precise). Structure analysis also flagged potential misclassifications. (Connects to Prompt: Needs clearer entity type definitions/constraints).

    **Recommendations for Prompt Improvement:**
    - **Reinforce Property Naming:** Be more strict, e.g., "ALL property names MUST be camelCase (e.g., `managedBy`, `dependsOn`)."
    - **Strengthen Alignment Instructions:** Explicitly map ambiguous terms identified in domain analysis. E.g., "Map 'legacy system' components to the existing `:SoftwareModule` class." or "If 'Manager' refers to a role title, create an instance of `:Role`; if it refers to a person holding the role, create an instance of `:Employee` and link via a `:hasRole` property."
    - **Provide Examples:** Include a short example within the prompt showing desired TTL output, including correct property casing and alignment.
    - **Clarify Entity Definitions:** Briefly reiterate the expected types for key entities (e.g., "Ensure `Projects` are instances of `:Project`, `Teams` of `:Team`").
    - **Address Acronyms:** Instruct the LLM on how to handle known acronyms, e.g., "Expand known acronyms like 'QMS' to 'QualityManagementSystem' when creating URIs, or link to a predefined :Acronym class."
    """
    # llm_response = analysis_chain.invoke(input_data) # Actual LLM call
    llm_response = mock_analysis # Use mock response
    # --- End Mock LLM Call ---


    state['analysis_summary'] = llm_response
    state['messages'].append(AIMessage(content=f"Analysis Complete:\n{llm_response}"))
    print("--- analyze_performance complete ---")
    print(f"Analysis Summary:\n{llm_response}")
    return state

def generate_new_prompt(state: AgentState) -> AgentState:
    """Generates a new, improved prompt based on the analysis."""
    print("\n--- Node: generate_new_prompt ---")

    if not state.get('analysis_summary') or "Analysis skipped" in state['analysis_summary']:
         state['suggested_prompt'] = "Prompt generation skipped: Analysis was not performed."
         state['messages'].append(AIMessage(content=state['suggested_prompt']))
         print(state['suggested_prompt'])
         return state
    if not state.get('current_prompt_text'):
        state['suggested_prompt'] = "Prompt generation skipped: Current prompt text is missing."
        state['messages'].append(AIMessage(content=state['suggested_prompt']))
        print(state['suggested_prompt'])
        return state

    prompt_generation_template = ChatPromptTemplate.from_messages([
        ("system", """You are an expert prompt engineer. Your task is to revise an existing prompt based on an analysis of its previous performance.
        Incorporate the recommendations from the analysis to create a clearer, more effective prompt for ontology extraction and alignment.
        Retain the core goal but address the identified weaknesses. Be specific and actionable.
        Ensure the new prompt is well-structured and easy for an LLM to understand.
        Output *only* the revised prompt text, nothing else."""),
        ("human", """Revise the following prompt based on the analysis and recommendations provided.

        **Original Prompt (Version {prompt_version_to_improve}):**
        ```
        {current_prompt_text}
        ```

        **Analysis and Recommendations:**
        {analysis_summary}

        **Revised Prompt:**
        """)
    ])

    generation_chain = prompt_generation_template | llm | StrOutputParser()

    input_data = {
        "prompt_version_to_improve": state['prompt_version_to_improve'],
        "current_prompt_text": state['current_prompt_text'],
        "analysis_summary": state['analysis_summary'],
    }


    # --- Mock LLM Call ---
    print("--- Simulating LLM call for prompt generation ---")
    # Based on the mock analysis, a potential revised prompt:
    mock_revised_prompt = f"""
    **Task:** Extract named entities and relationships from the provided business document to expand/align our ontology.

    **Input:** Business document text.
    **Output:** Valid TTL triples using the namespace `http://example.org/` (prefix `:`).

    **Entities to Extract:**
    *   People (map to `:Employee` if possible, otherwise `:Person`)
    *   Projects (map to `:Project`)
    *   Teams (map to `:Team`)
    *   Products (map to `:Product`)
    *   Features (map to `:Feature`)
    *   Software Components/Modules (map to existing class `:SoftwareModule`)
        *   **Crucially:** Map terms like "legacy system component" or specific component names explicitly to `:SoftwareModule`.

    **Relationships to Extract:**
    *   `managedBy` (Project -> Team, Employee -> Employee)
    *   `reportsTo` (Employee -> Employee)
    *   `dependsOn` (Feature -> Component, Project -> Project)
    *   `uses` (Project -> Component, Product -> Component)
    *   `partOf` (Component -> Component, Team -> Department)
    *   `hasRole` (Employee -> Role) - Use this if a specific role title (e.g., 'Manager') is mentioned for a person. Create a separate `:Role` instance if needed.

    **Formatting and Ontology Alignment Rules:**
    1.  **Strict TTL:** Output MUST be valid TTL syntax.
    2.  **Namespace:** Use `@prefix : <http://example.org/> .`
    3.  **Property Naming:** ALL property names MUST be strictly camelCase (e.g., `managedBy`, `reportsTo`). NO underscores or PascalCase for properties.
    4.  **Class Alignment:** Align extracted entities to the specified target classes (e.g., `:Employee`, `:Project`, `:Team`, `:SoftwareModule`, `:Feature`). Use these exact class names.
    5.  **Handle Ambiguity:**
        *   If 'Manager' refers to a job title/role contextually, create a `:Role` instance and link the relevant `:Employee` using `:hasRole`.
        *   Identify and map variations of software components (e.g., "legacy Software Component", "Component A") to the existing `:SoftwareModule` class.
    6.  **Acronyms:** For known acronyms like 'QMS', consider using the full name 'QualityManagementSystem' in URIs where appropriate (e.g., `:projectQMS`), or link to a dedicated :Acronym class if one exists in the target ontology.

    **Example Snippet Output:**
    ```ttl
    @prefix : <http://example.org/> .

    :projectX a :Project .
    :teamY a :Team .
    :projectX :managedBy :teamY .

    :janeSmith a :Employee .
    :managerRole a :Role ; :roleTitle "Manager" .
    :janeSmith :hasRole :managerRole .
    :teamY :hasMember :janeSmith . # Assuming relationship exists

    :componentA a :SoftwareModule . # Correctly aligned
    :featureZ a :Feature .
    :featureZ :dependsOn :componentA .
    ```
    """
    # llm_response = generation_chain.invoke(input_data) # Actual LLM call
    llm_response = mock_revised_prompt # Use mock response
    # --- End Mock LLM Call ---


    state['suggested_prompt'] = llm_response
    # Add the final suggestion as the last message
    state['messages'].append(AIMessage(content=f"Suggested Revised Prompt (Version {state['prompt_version_to_improve'] + 1}):\n{llm_response}"))
    print("--- generate_new_prompt complete ---")
    print(f"Suggested Prompt:\n{llm_response}")
    return state
